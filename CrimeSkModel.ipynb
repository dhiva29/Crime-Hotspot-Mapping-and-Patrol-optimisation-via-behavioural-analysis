{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhiva29/Crime-Hotspot-Mapping-and-Patrol-optimisation-via-behavioural-analysis/blob/main/CrimeSkModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uIIVt9Ss9q7R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcxAWzsE-FfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa8b92e-b219-4e19-af63-e41798d69cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "--2025-03-29 04:37:53--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.2.1/cloudflared-linux-amd64 [following]\n",
            "--2025-03-29 04:37:53--  https://github.com/cloudflare/cloudflared/releases/download/2025.2.1/cloudflared-linux-amd64\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/eac8237f-c554-46b5-95ea-f2f5873e69a5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250329%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250329T043753Z&X-Amz-Expires=300&X-Amz-Signature=c6d4977aeb3af9c2cf02a5e92939d744e5a4e4a624c90bd26c0fadfc2d79a157&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-03-29 04:37:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/eac8237f-c554-46b5-95ea-f2f5873e69a5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250329%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250329T043753Z&X-Amz-Expires=300&X-Amz-Signature=c6d4977aeb3af9c2cf02a5e92939d744e5a4e4a624c90bd26c0fadfc2d79a157&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37844205 (36M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared’\n",
            "\n",
            "cloudflared         100%[===================>]  36.09M   175MB/s    in 0.2s    \n",
            "\n",
            "2025-03-29 04:37:54 (175 MB/s) - ‘cloudflared’ saved [37844205/37844205]\n",
            "\n",
            "\u001b[90m2025-03-29T04:37:55Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-03-29T04:37:55Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m |  https://eco-ak-chubby-mlb.trycloudflare.com                                               |\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.2.1 (Checksum afdfadd1ef552e66bffc35246fe30a9bd578356d2d386de95585ccfc432472b8)\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.22.10, GoArch: amd64\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/run-tunnel/as-a-service/\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 07be9b5e-2284-4a52-9b05-a9f2c2a84cd7\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m Using [CurveID(4588) CurveID(25497) CurveP256] as curve preferences \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.77\n",
            "2025/03/29 04:38:09 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-03-29T04:38:09Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m02cda3d9-9595-4b81-950f-f9c159caa717 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.77 \u001b[36mlocation=\u001b[0mlax09 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 41 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 41 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://eco-ak-chubby-mlb.trycloudflare.com/static/js/index.C4j9kiPf.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.77 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 65 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 65 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://eco-ak-chubby-mlb.trycloudflare.com/static/media/SourceSansPro-Bold.-6c9oR8J.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.77 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 77 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 77 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://eco-ak-chubby-mlb.trycloudflare.com/static/media/SourceSansPro-SemiBold.sKQIyTMz.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.77 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 69 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 69 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://eco-ak-chubby-mlb.trycloudflare.com/static/media/SourceSansPro-Regular.DZLUzqI4.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.77 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 49 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 49 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://eco-ak-chubby-mlb.trycloudflare.com/static/js/index.C4j9kiPf.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.77 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 45 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 45 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://eco-ak-chubby-mlb.trycloudflare.com/static/media/SourceSansPro-SemiBold.sKQIyTMz.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.77 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 57 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 57 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://eco-ak-chubby-mlb.trycloudflare.com/static/media/SourceSansPro-Regular.DZLUzqI4.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.77 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 61 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:8501\n",
            "\u001b[90m2025-03-29T04:40:32Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 61 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://eco-ak-chubby-mlb.trycloudflare.com/static/media/SourceSansPro-Bold.-6c9oR8J.woff2 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.77 \u001b[36mtype=\u001b[0mhttp\n"
          ]
        }
      ],
      "source": [
        "# Install Streamlit (already installed, but included for completeness)\n",
        "!pip install streamlit\n",
        "\n",
        "# Install Cloudflared for tunneling\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
        "!chmod +x cloudflared\n",
        "\n",
        "# Kill any existing Streamlit and Cloudflared processes to avoid conflicts\n",
        "!pkill streamlit\n",
        "!pkill cloudflared\n",
        "\n",
        "# Write the Streamlit app to a file (app.py)\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write('''\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import folium\n",
        "from folium.plugins import HeatMap, MiniMap\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(layout=\"wide\", initial_sidebar_state=\"expanded\")\n",
        "\n",
        "# Load the data\n",
        "file_path = '/content/coimbatore_city_crime_data_spatial.xlsx'\n",
        "if not os.path.exists(file_path):\n",
        "    st.error(f\"Data file not found at {file_path}. Please ensure the file is uploaded.\")\n",
        "    st.stop()\n",
        "else:\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "# Convert 'date' to datetime (Excel serial dates)\n",
        "if not pd.api.types.is_datetime64_any_dtype(df['date']):\n",
        "    if pd.api.types.is_numeric_dtype(df['date']):\n",
        "        df['date'] = pd.to_datetime(df['date'], origin='1899-12-30', unit='d')\n",
        "    else:\n",
        "        raise ValueError(\"The 'date' column is neither datetime nor numeric. Please check the data.\")\n",
        "\n",
        "# Extract year and month from date\n",
        "df['year'] = df['date'].dt.year\n",
        "df['month'] = df['date'].dt.month\n",
        "\n",
        "# Prepare data for crime occurrence prediction\n",
        "min_date = df['date'].min()\n",
        "max_date = df['date'].max()\n",
        "areas = df['area'].unique()\n",
        "date_range = pd.date_range(start=min_date, end=max_date)\n",
        "index = pd.MultiIndex.from_product([areas, date_range], names=['area', 'date'])\n",
        "daily_crimes = df.groupby(['area', 'date'])['incidents'].sum().reset_index()\n",
        "all_dates = pd.DataFrame(index=index).reset_index()\n",
        "all_dates = all_dates.merge(daily_crimes, on=['area', 'date'], how='left')\n",
        "all_dates['incidents'] = all_dates['incidents'].fillna(0)\n",
        "all_dates['crime_occurred'] = (all_dates['incidents'] > 0).astype(int)\n",
        "\n",
        "# Extract features for occurrence prediction\n",
        "all_dates['year'] = all_dates['date'].dt.year\n",
        "all_dates['month'] = all_dates['date'].dt.month\n",
        "all_dates['day'] = all_dates['date'].dt.day\n",
        "all_dates['day_of_week'] = all_dates['date'].dt.dayofweek\n",
        "all_dates = pd.get_dummies(all_dates, columns=['area'], prefix='area')\n",
        "\n",
        "# Features and target for occurrence model\n",
        "X_occ = all_dates.drop(['date', 'incidents', 'crime_occurred'], axis=1)\n",
        "y_occ = all_dates['crime_occurred']\n",
        "\n",
        "# Train-test split (time-based)\n",
        "train_mask = all_dates['date'] < '2022-01-01'\n",
        "X_occ_train = X_occ[train_mask]\n",
        "y_occ_train = y_occ[train_mask]\n",
        "X_occ_test = X_occ[~train_mask]\n",
        "y_occ_test = y_occ[~train_mask]\n",
        "\n",
        "# Train crime occurrence model\n",
        "model_occurrence = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "model_occurrence.fit(X_occ_train, y_occ_train)\n",
        "\n",
        "# Streamlit app layout\n",
        "st.title(\"Coimbatore City Crime Dashboard\")\n",
        "st.sidebar.title(\"Navigation\")\n",
        "page = st.sidebar.selectbox(\"Select a Page\", [\"Home\", \"Crime Mapping\", \"Interactive Dashboard\", \"Behavioral Analysis\", \"Patrol Optimization\"])\n",
        "\n",
        "# Home Page\n",
        "if page == \"Home\":\n",
        "    st.header(\"Welcome to the Cyber Crime Dashboard\")\n",
        "    st.write(\"Select an option from the sidebar to explore crime data for Coimbatore City (2020–2022).\")\n",
        "    st.markdown(\"\"\"\n",
        "    - **Crime Mapping**: Visualize crime patterns with different mapping techniques.\n",
        "    - **Interactive Dashboard**: Explore crime trends over time with filters.\n",
        "    - **Behavioral Analysis**: Predict crime types and occurrences using machine learning.\n",
        "    - **Patrol Optimization**: Identify patrol areas with crime predictions.\n",
        "    \"\"\")\n",
        "\n",
        "# Crime Mapping\n",
        "elif page == \"Crime Mapping\":\n",
        "    st.header(\"Crime Mapping with Layer Buttons\")\n",
        "    center_lat = df['latitude'].mean()\n",
        "    center_long = df['longitude'].mean()\n",
        "\n",
        "    # Define map styles with explicit tile URLs for reliability\n",
        "    map_styles = {\n",
        "        \"CartoDB Voyager\": {\n",
        "            \"tiles\": \"https://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}{r}.png\",\n",
        "            \"attr\": 'Map tiles by <a href=\"https://cartodb.com/attributions\">CartoDB</a>, under <a href=\"http://creativecommons.org/licenses/by/3.0\">CC BY 3.0</a>. Data by <a href=\"http://openstreetmap.org\">OpenStreetMap</a>, under <a href=\"http://www.openstreetmap.org/copyright\">ODbL</a>.'\n",
        "        },\n",
        "        \"OpenStreetMap\": {\n",
        "            \"tiles\": \"https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",\n",
        "            \"attr\": 'Map data © <a href=\"http://openstreetmap.org\">OpenStreetMap</a> contributors'\n",
        "        },\n",
        "        \"Stamen Terrain\": {\n",
        "            \"tiles\": \"https://stamen-tiles-{s}.a.ssl.fastly.net/terrain/{z}/{x}/{y}.jpg\",\n",
        "            \"attr\": 'Map tiles by <a href=\"http://stamen.com\">Stamen Design</a>, under <a href=\"http://creativecommons.org/licenses/by/3.0\">CC BY 3.0</a>. Data by <a href=\"http://openstreetmap.org\">OpenStreetMap</a>, under <a href=\"http://www.openstreetmap.org/copyright\">ODbL</a>.'\n",
        "        },\n",
        "        \"CartoDB Positron\": {\n",
        "            \"tiles\": \"https://{s}.basemaps.cartocdn.com/light_nolabels/{z}/{x}/{y}{r}.png\",\n",
        "            \"attr\": 'Map tiles by <a href=\"https://cartodb.com/attributions\">CartoDB</a>, under <a href=\"http://creativecommons.org/licenses/by/3.0\">CC BY 3.0</a>. Data by <a href=\"http://openstreetmap.org\">OpenStreetMap</a>, under <a href=\"http://www.openstreetmap.org/copyright\">ODbL</a>.'\n",
        "        }\n",
        "    }\n",
        "    selected_map_style = st.selectbox(\"Select Map Style\", list(map_styles.keys()), index=1)  # Default to OpenStreetMap\n",
        "\n",
        "    # Create the map with the selected basemap\n",
        "    try:\n",
        "        m = folium.Map(\n",
        "            location=[center_lat, center_long],\n",
        "            zoom_start=12,\n",
        "            tiles=map_styles[selected_map_style][\"tiles\"],\n",
        "            attr=map_styles[selected_map_style][\"attr\"]\n",
        "        )\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to load map tiles for {selected_map_style}: {str(e)}.\")\n",
        "        st.write(\"Falling back to OpenStreetMap as a default basemap.\")\n",
        "        m = folium.Map(\n",
        "            location=[center_lat, center_long],\n",
        "            zoom_start=12,\n",
        "            tiles=\"https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",\n",
        "            attr='Map data © <a href=\"http://openstreetmap.org\">OpenStreetMap</a> contributors'\n",
        "        )\n",
        "\n",
        "    # Add a MiniMap\n",
        "    try:\n",
        "        minimap = MiniMap()\n",
        "        m.add_child(minimap)\n",
        "    except Exception as e:\n",
        "        st.warning(\"MiniMap could not be added due to tile loading issues.\")\n",
        "\n",
        "    # Thematic Mapping Layer\n",
        "    thematic_layer = folium.FeatureGroup(name=\"Thematic Mapping\", show=True)\n",
        "    for area, group in df.groupby('area'):\n",
        "        total_incidents = group['incidents'].sum()\n",
        "        avg_lat = group['latitude'].mean()\n",
        "        avg_long = group['longitude'].mean()\n",
        "        folium.Marker(\n",
        "            location=[avg_lat, avg_long],\n",
        "            popup=f\"{area}: {total_incidents} incidents\",\n",
        "            icon=folium.Icon(color=\"blue\")\n",
        "        ).add_to(thematic_layer)\n",
        "    thematic_layer.add_to(m)\n",
        "\n",
        "    # Non-Graphical Indicators Layer\n",
        "    crime_counts = df['crime_type'].value_counts().to_dict()\n",
        "    non_graphical_layer = folium.FeatureGroup(name=\"Non-Graphical Indicators\", show=False)\n",
        "    folium.Marker(\n",
        "        location=[center_lat, center_long],\n",
        "        popup=str(crime_counts),\n",
        "        icon=folium.Icon(color=\"green\")\n",
        "    ).add_to(non_graphical_layer)\n",
        "    non_graphical_layer.add_to(m)\n",
        "\n",
        "    # Hot Spot Analysis Layer\n",
        "    hotspot_layer = folium.FeatureGroup(name=\"Hot Spot Analysis\", show=False)\n",
        "    heat_data = [[row['latitude'], row['longitude'], row['incidents']] for _, row in df.iterrows()]\n",
        "    # Convert float keys to strings to avoid rendering issues\n",
        "    gradient = {str(k): v for k, v in {0.4: 'blue', 0.65: 'yellow', 1: 'red'}.items()}\n",
        "    HeatMap(\n",
        "        heat_data,\n",
        "        radius=20,\n",
        "        blur=10,\n",
        "        gradient=gradient\n",
        "    ).add_to(hotspot_layer)\n",
        "    hotspot_layer.add_to(m)\n",
        "\n",
        "    # Spatial Regression Layer\n",
        "    spatial_regression_layer = folium.FeatureGroup(name=\"Spatial Regression\", show=False)\n",
        "    for area, group in df.groupby('area'):\n",
        "        total_incidents = group['incidents'].sum()\n",
        "        avg_lat = group['latitude'].mean()\n",
        "        avg_long = group['longitude'].mean()\n",
        "        if total_incidents > 5:\n",
        "            folium.Marker(\n",
        "                location=[avg_lat, avg_long],\n",
        "                popup=f\"{area}: High Risk (Predicted)\",\n",
        "                icon=folium.Icon(color=\"purple\")\n",
        "            ).add_to(spatial_regression_layer)\n",
        "    spatial_regression_layer.add_to(m)\n",
        "\n",
        "    # Geographic Profiling Layer\n",
        "    geo_profiling_layer = folium.FeatureGroup(name=\"Geographic Profiling\", show=False)\n",
        "    murder_data = [[row['latitude'], row['longitude']] for _, row in df[df['crime_type'] == 'Murder'].iterrows()]\n",
        "    # Convert float keys to strings to avoid rendering issues\n",
        "    gradient = {str(k): v for k, v in {0.4: 'blue', 0.65: 'yellow', 1: 'red'}.items()}\n",
        "    HeatMap(\n",
        "        murder_data,\n",
        "        radius=20,\n",
        "        blur=10,\n",
        "        gradient=gradient\n",
        "    ).add_to(geo_profiling_layer)\n",
        "    geo_profiling_layer.add_to(m)\n",
        "\n",
        "    # Add layer control\n",
        "    folium.LayerControl().add_to(m)\n",
        "\n",
        "    # Render the map in Streamlit\n",
        "    with st.spinner(\"Loading map...\"):\n",
        "        try:\n",
        "            st.components.v1.html(m._repr_html_(), height=600)\n",
        "        except Exception as e:\n",
        "            st.error(f\"Failed to render map in Streamlit: {str(e)}.\")\n",
        "            st.write(\"As a workaround, the map has been saved as 'crime_mapping.html'. Please open it in a browser to view the map.\")\n",
        "            try:\n",
        "                m.save(\"crime_mapping.html\")\n",
        "            except Exception as save_error:\n",
        "                st.error(f\"Failed to save map as HTML: {str(save_error)}.\")\n",
        "\n",
        "# Interactive Dashboard\n",
        "elif page == \"Interactive Dashboard\":\n",
        "    st.header(\"Interactive Dashboard (2020–2022)\")\n",
        "\n",
        "    col1, col2, col3, col4 = st.columns([2, 2, 2, 2])\n",
        "    with col1:\n",
        "        total_incidents = df['incidents'].sum()\n",
        "        st.metric(\"Total Incidents\", f\"{total_incidents:,}\")\n",
        "    with col2:\n",
        "        most_common_crime = df['crime_type'].mode()[0]\n",
        "        st.metric(\"Most Common Crime\", most_common_crime)\n",
        "    with col3:\n",
        "        most_affected_area = df.groupby('area')['incidents'].sum().idxmax()\n",
        "        st.metric(\"Most Affected Area\", most_affected_area)\n",
        "    with col4:\n",
        "        total_crime_types = df['crime_type'].nunique()\n",
        "        st.metric(\"Total Crime Types\", total_crime_types)\n",
        "\n",
        "    col1, col2, col3, col4 = st.columns([2, 2, 2, 2])\n",
        "    with col1:\n",
        "        year_options = ['All Years'] + sorted(df['year'].unique().tolist())\n",
        "        selected_year = st.selectbox(\"Select Year\", year_options)\n",
        "    with col2:\n",
        "        crime_options = ['All Crimes'] + sorted(df['crime_type'].unique().tolist())\n",
        "        selected_crime = st.selectbox(\"Select Crime Type\", crime_options)\n",
        "    with col3:\n",
        "        area_options = ['All Areas'] + sorted(df['area'].unique().tolist())\n",
        "        selected_area = st.selectbox(\"Select Area\", area_options)\n",
        "    with col4:\n",
        "        date_range = st.slider(\n",
        "            \"Select Date Range\",\n",
        "            min_value=df['date'].min().to_pydatetime(),\n",
        "            max_value=df['date'].max().to_pydatetime(),\n",
        "            value=(df['date'].min().to_pydatetime(), df['date'].max().to_pydatetime()),\n",
        "            format=\"YYYY-MM-DD\"\n",
        "        )\n",
        "\n",
        "    filtered_df = df.copy()\n",
        "    if selected_year != 'All Years':\n",
        "        filtered_df = filtered_df[filtered_df['year'] == selected_year]\n",
        "    if selected_crime != 'All Crimes':\n",
        "        filtered_df = filtered_df[filtered_df['crime_type'] == selected_crime]\n",
        "    if selected_area != 'All Areas':\n",
        "        filtered_df = filtered_df[filtered_df['area'] == selected_area]\n",
        "    filtered_df = filtered_df[\n",
        "        (filtered_df['date'] >= pd.to_datetime(date_range[0])) &\n",
        "        (filtered_df['date'] <= pd.to_datetime(date_range[1]))\n",
        "    ]\n",
        "\n",
        "    col1, col2 = st.columns([1, 3])\n",
        "    with col1:\n",
        "        st.subheader(\"Top 10 Crime-Occurring Areas\")\n",
        "        area_incidents = df.groupby('area')['incidents'].sum().reset_index()\n",
        "        prev_year = df['year'].max() - 1\n",
        "        prev_year_df = df[df['year'] == prev_year].groupby('area')['incidents'].sum().reset_index()\n",
        "        prev_year_df.rename(columns={'incidents': 'prev_incidents'}, inplace=True)\n",
        "        area_incidents = area_incidents.merge(prev_year_df, on='area', how='left')\n",
        "        area_incidents['prev_incidents'] = area_incidents['prev_incidents'].fillna(0)\n",
        "        area_incidents['change'] = ((area_incidents['incidents'] - area_incidents['prev_incidents']) / area_incidents['prev_incidents'] * 100).replace([float('inf'), -float('inf')], 0)\n",
        "        top_10_areas = area_incidents.sort_values(by='incidents', ascending=False).head(10)\n",
        "        table_data = []\n",
        "        for _, row in top_10_areas.iterrows():\n",
        "            trend = \"🔺\" if row['change'] > 0 else \"🔻\" if row['change'] < 0 else \"➖\"\n",
        "            trend_color = \"red\" if row['change'] > 0 else \"orange\" if row['change'] < 0 else \"grey\"\n",
        "            table_data.append({\n",
        "                \"Area\": row['area'],\n",
        "                \"Incidents\": f\"{int(row['incidents']):,}\",\n",
        "                \"Trend\": f\"<span style='color:{trend_color}'>{trend} {row['change']:.1f}%</span>\"\n",
        "            })\n",
        "        st.write(pd.DataFrame(table_data).to_html(escape=False, index=False), unsafe_allow_html=True)\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Crime Trends Over Time\")\n",
        "        trend_df = filtered_df.groupby(['date', 'crime_type'])['incidents'].sum().reset_index()\n",
        "        fig_trend = px.line(\n",
        "            trend_df,\n",
        "            x='date',\n",
        "            y='incidents',\n",
        "            color='crime_type',\n",
        "            title='Crime Incidents Over Time by Type',\n",
        "            labels={'incidents': 'Number of Incidents', 'date': 'Date'},\n",
        "            height=400\n",
        "        )\n",
        "        fig_trend.update_layout(\n",
        "            legend_title_text='Crime Type',\n",
        "            xaxis_title=\"Date\",\n",
        "            yaxis_title=\"Number of Incidents\",\n",
        "            hovermode=\"x unified\"\n",
        "        )\n",
        "        st.plotly_chart(fig_trend, use_container_width=True)\n",
        "\n",
        "        st.subheader(\"Geographical Distribution of Crimes\")\n",
        "        center_lat = df['latitude'].mean()\n",
        "        center_long = df['longitude'].mean()\n",
        "        m = folium.Map(\n",
        "            location=[center_lat, center_long],\n",
        "            zoom_start=12,\n",
        "            tiles='Stamen Terrain',\n",
        "            attr='Map tiles by <a href=\"http://stamen.com\">Stamen Design</a>, under <a href=\"http://creativecommons.org/licenses/by/3.0\">CC BY 3.0</a>. Data by <a href=\"http://openstreetmap.org\">OpenStreetMap</a>, under <a href=\"http://www.openstreetmap.org/copyright\">ODbL</a>.'\n",
        "        )\n",
        "        minimap = MiniMap()\n",
        "        m.add_child(minimap)\n",
        "        heat_data = [[row['latitude'], row['longitude'], row['incidents']] for _, row in filtered_df.iterrows()]\n",
        "        HeatMap(heat_data, radius=20, blur=10).add_to(m)\n",
        "        with st.spinner(\"Loading map...\"):\n",
        "            st.components.v1.html(m._repr_html_(), height=400)\n",
        "\n",
        "    st.subheader(\"Crime Type Distribution\")\n",
        "    crime_dist = filtered_df.groupby('crime_type')['incidents'].sum().reset_index()\n",
        "    fig_dist = px.bar(\n",
        "        crime_dist,\n",
        "        x='incidents',\n",
        "        y='crime_type',\n",
        "        orientation='h',\n",
        "        title='Distribution of Crime Types',\n",
        "        labels={'incidents': 'Number of Incidents', 'crime_type': 'Crime Type'},\n",
        "        height=300\n",
        "    )\n",
        "    fig_dist.update_layout(\n",
        "        xaxis_title=\"Number of Incidents\",\n",
        "        yaxis_title=\"Crime Type\",\n",
        "        showlegend=False\n",
        "    )\n",
        "    st.plotly_chart(fig_dist, use_container_width=True)\n",
        "\n",
        "# Behavioral Analysis\n",
        "elif page == \"Behavioral Analysis\":\n",
        "    st.header(\"Behavioral Analysis\")\n",
        "\n",
        "    # Crime Type Prediction Model\n",
        "    X_type = df[['year', 'month', 'latitude', 'longitude']]\n",
        "    y_type = df['crime_type']\n",
        "    X_type_train, X_type_test, y_type_train, y_type_test = train_test_split(X_type, y_type, test_size=0.2, random_state=42)\n",
        "    model_type = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "    model_type.fit(X_type_train, y_type_train)\n",
        "    type_accuracy = model_type.score(X_type_test, y_type_test)\n",
        "\n",
        "    # Crime Occurrence Prediction Accuracy\n",
        "    occ_accuracy = model_occurrence.score(X_occ_test, y_occ_test)\n",
        "\n",
        "    st.markdown(\"### Crime Occurrence Prediction\")\n",
        "    st.write(f\"Model Accuracy: {occ_accuracy:.2f}\")\n",
        "    selected_area = st.selectbox(\"Select Area\", areas)\n",
        "    selected_date = st.date_input(\"Select Date\", value=datetime.date.today())\n",
        "    input_occ = pd.DataFrame({'area': [selected_area], 'date': [pd.to_datetime(selected_date)]})\n",
        "    input_occ['year'] = input_occ['date'].dt.year\n",
        "    input_occ['month'] = input_occ['date'].dt.month\n",
        "    input_occ['day'] = input_occ['date'].dt.day\n",
        "    input_occ['day_of_week'] = input_occ['date'].dt.dayofweek\n",
        "    input_occ = pd.get_dummies(input_occ, columns=['area'], prefix='area')\n",
        "    for col in X_occ_train.columns:\n",
        "        if col not in input_occ.columns:\n",
        "            input_occ[col] = 0\n",
        "    input_occ = input_occ[X_occ_train.columns]\n",
        "    prob = model_occurrence.predict_proba(input_occ)[:, 1][0]\n",
        "    st.write(f\"Predicted Probability of Crime Occurrence: {prob:.2f}\")\n",
        "\n",
        "    st.markdown(\"### Crime Type Prediction\")\n",
        "    st.write(f\"Model Accuracy: {type_accuracy:.2f}\")\n",
        "    lat = df[df['area'] == selected_area]['latitude'].iloc[0]\n",
        "    long = df[df['area'] == selected_area]['longitude'].iloc[0]\n",
        "    input_type = pd.DataFrame({\n",
        "        'year': [selected_date.year],\n",
        "        'month': [selected_date.month],\n",
        "        'latitude': [lat],\n",
        "        'longitude': [long]\n",
        "    })\n",
        "    predicted_type = model_type.predict(input_type)[0]\n",
        "    st.write(f\"Predicted Most Likely Crime Type: {predicted_type}\")\n",
        "\n",
        "    # Feature Importance for Crime Type Model\n",
        "    importances = pd.DataFrame({'feature': X_type.columns, 'importance': model_type.feature_importances_})\n",
        "    st.write(\"Feature Importance for Crime Type Prediction:\")\n",
        "    st.dataframe(importances.sort_values(by='importance', ascending=False))\n",
        "\n",
        "# Patrol Optimization\n",
        "# Patrol Optimization\n",
        "elif page == \"Patrol Optimization\":\n",
        "    st.header(\"Patrol Optimization\")\n",
        "\n",
        "    # Metrics at the top (consistent with dashboard theme)\n",
        "    col1, col2, col3, col4 = st.columns([2, 2, 2, 2])\n",
        "    with col1:\n",
        "        total_incidents = df['incidents'].sum()\n",
        "        st.metric(\"Total Incidents\", f\"{total_incidents:,}\")\n",
        "    with col2:\n",
        "        most_common_crime = df['crime_type'].mode()[0]\n",
        "        st.metric(\"Most Common Crime\", most_common_crime)\n",
        "    with col3:\n",
        "        most_affected_area = df.groupby('area')['incidents'].sum().idxmax()\n",
        "        st.metric(\"Most Affected Area\", most_affected_area)\n",
        "    with col4:\n",
        "        total_crime_types = df['crime_type'].nunique()\n",
        "        st.metric(\"Total Crime Types\", total_crime_types)\n",
        "\n",
        "    # Date input for prediction\n",
        "    current_time = datetime.datetime.now()\n",
        "    st.write(f\"Current Date and Time: {current_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    selected_date = st.date_input(\"Select Date for Prediction\", value=current_time.date())\n",
        "\n",
        "    # Step 1: Create pred_df with 'area' and 'date'\n",
        "    pred_df = pd.DataFrame({'area': areas, 'date': [pd.to_datetime(selected_date)] * len(areas)})\n",
        "    pred_df['year'] = pred_df['date'].dt.year\n",
        "    pred_df['month'] = pred_df['date'].dt.month\n",
        "    pred_df['day'] = pred_df['date'].dt.day\n",
        "    pred_df['day_of_week'] = pred_df['date'].dt.dayofweek\n",
        "\n",
        "    # Step 2: Create a copy for prediction with one-hot encoding\n",
        "    pred_df_for_pred = pred_df.copy()\n",
        "    pred_df_for_pred = pd.get_dummies(pred_df_for_pred, columns=['area'], prefix='area')\n",
        "\n",
        "    # Step 3: Align columns with X_occ_train for prediction\n",
        "    for col in X_occ_train.columns:\n",
        "        if col not in pred_df_for_pred.columns:\n",
        "            pred_df_for_pred[col] = 0\n",
        "    pred_df_for_pred = pred_df_for_pred[X_occ_train.columns]\n",
        "\n",
        "    # Step 4: Make predictions\n",
        "    probs = model_occurrence.predict_proba(pred_df_for_pred)[:, 1]\n",
        "\n",
        "    # Step 5: Add predictions back to the original pred_df\n",
        "    pred_df['probability'] = probs\n",
        "\n",
        "    # Step 6: Merge with area_latlong to get latitude and longitude\n",
        "    area_latlong = df.groupby('area')[['latitude', 'longitude']].first().reset_index()\n",
        "    pred_df = pred_df.merge(area_latlong, on='area', how='left')\n",
        "\n",
        "    # Step 7: Automatic Patrol Scheduling\n",
        "    st.subheader(\"Patrol Scheduling\")\n",
        "    patrol_units = [\"Unit 1\", \"Unit 2\", \"Unit 3\"]\n",
        "    top_5 = pred_df.sort_values(by='probability', ascending=False).head(5)\n",
        "    assignments = {}\n",
        "    for i, unit in enumerate(patrol_units):\n",
        "        if i < len(top_5):\n",
        "            assigned_area = top_5.iloc[i]['area']\n",
        "            assignments[unit] = assigned_area\n",
        "    if assignments:\n",
        "        st.write(\"Patrol Assignments:\")\n",
        "        st.write(assignments)\n",
        "    else:\n",
        "        st.write(\"No high-risk areas to assign.\")\n",
        "\n",
        "    # Step 8: Alert System for High-Risk Areas\n",
        "    high_risk_threshold = 0.8\n",
        "    high_risk_areas = top_5[top_5['probability'] > high_risk_threshold]\n",
        "    if not high_risk_areas.empty:\n",
        "        st.error(f\"🚨 High-Risk Alert: The following areas have a crime probability above {high_risk_threshold}: {', '.join(high_risk_areas['area'])}\")\n",
        "\n",
        "    # Step 9: Create Map with Heatmap\n",
        "    st.subheader(\"Predicted Crime Hotspots\")\n",
        "    center_lat = df['latitude'].mean()\n",
        "    center_long = df['longitude'].mean()\n",
        "\n",
        "    # Define map styles with explicit tile URLs for reliability\n",
        "    map_styles = {\n",
        "        \"CartoDB Voyager\": {\n",
        "            \"tiles\": \"https://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}{r}.png\",\n",
        "            \"attr\": 'Map tiles by <a href=\"https://cartodb.com/attributions\">CartoDB</a>, under <a href=\"http://creativecommons.org/licenses/by/3.0\">CC BY 3.0</a>. Data by <a href=\"http://openstreetmap.org\">OpenStreetMap</a>, under <a href=\"http://www.openstreetmap.org/copyright\">ODbL</a>.'\n",
        "        },\n",
        "        \"OpenStreetMap\": {\n",
        "            \"tiles\": \"https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",\n",
        "            \"attr\": 'Map data © <a href=\"http://openstreetmap.org\">OpenStreetMap</a> contributors'\n",
        "        },\n",
        "        \"Stamen Terrain\": {\n",
        "            \"tiles\": \"https://stamen-tiles-{s}.a.ssl.fastly.net/terrain/{z}/{x}/{y}.jpg\",\n",
        "            \"attr\": 'Map tiles by <a href=\"http://stamen.com\">Stamen Design</a>, under <a href=\"http://creativecommons.org/licenses/by/3.0\">CC BY 3.0</a>. Data by <a href=\"http://openstreetmap.org\">OpenStreetMap</a>, under <a href=\"http://www.openstreetmap.org/copyright\">ODbL</a>.'\n",
        "        },\n",
        "        \"CartoDB Positron\": {\n",
        "            \"tiles\": \"https://{s}.basemaps.cartocdn.com/light_nolabels/{z}/{x}/{y}{r}.png\",\n",
        "            \"attr\": 'Map tiles by <a href=\"https://cartodb.com/attributions\">CartoDB</a>, under <a href=\"http://creativecommons.org/licenses/by/3.0\">CC BY 3.0</a>. Data by <a href=\"http://openstreetmap.org\">OpenStreetMap</a>, under <a href=\"http://www.openstreetmap.org/copyright\">ODbL</a>.'\n",
        "        }\n",
        "    }\n",
        "    selected_map_style = st.selectbox(\"Select Map Style\", list(map_styles.keys()), index=1)  # Default to OpenStreetMap for reliability\n",
        "\n",
        "    # Create the map with the selected basemap\n",
        "    try:\n",
        "        m = folium.Map(\n",
        "            location=[center_lat, center_long],\n",
        "            zoom_start=12,\n",
        "            tiles=map_styles[selected_map_style][\"tiles\"],\n",
        "            attr=map_styles[selected_map_style][\"attr\"]\n",
        "        )\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to load map tiles for {selected_map_style}: {str(e)}.\")\n",
        "        st.write(\"Falling back to OpenStreetMap as a default basemap.\")\n",
        "        m = folium.Map(\n",
        "            location=[center_lat, center_long],\n",
        "            zoom_start=12,\n",
        "            tiles=\"https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",\n",
        "            attr='Map data © <a href=\"http://openstreetmap.org\">OpenStreetMap</a> contributors'\n",
        "        )\n",
        "\n",
        "    # Add a MiniMap\n",
        "    try:\n",
        "        minimap = MiniMap()\n",
        "        m.add_child(minimap)\n",
        "    except Exception as e:\n",
        "        st.warning(\"MiniMap could not be added due to tile loading issues.\")\n",
        "\n",
        "    # Add a Heatmap to represent crime probabilities with fixed gradient keys\n",
        "    heat_data = [[row['latitude'], row['longitude'], row['probability']] for _, row in pred_df.iterrows()]\n",
        "    # Convert float keys to strings to avoid rendering issues\n",
        "    gradient = {str(k): v for k, v in {0.4: 'blue', 0.65: 'yellow', 1: 'red'}.items()}\n",
        "    HeatMap(\n",
        "        heat_data,\n",
        "        min_opacity=0.2,\n",
        "        radius=25,\n",
        "        blur=15,\n",
        "        gradient=gradient\n",
        "    ).add_to(m)\n",
        "\n",
        "    # Dynamic Patrol Routes with Color-Coding\n",
        "    top_5_coords = [(row['latitude'], row['longitude'], row['probability']) for _, row in top_5.iterrows()]\n",
        "    if len(top_5_coords) > 1:\n",
        "        # Simple nearest neighbor approach for route\n",
        "        route = [top_5_coords[0]]\n",
        "        remaining = top_5_coords[1:]\n",
        "        while remaining:\n",
        "            last_point = route[-1]\n",
        "            distances = [(i, ((p[0] - last_point[0])**2 + (p[1] - last_point[1])**2)**0.5) for i, p in enumerate(remaining)]\n",
        "            next_idx = min(distances, key=lambda x: x[1])[0]\n",
        "            route.append(remaining.pop(next_idx))\n",
        "\n",
        "        # Color-code the route segments based on probability\n",
        "        for i in range(len(route) - 1):\n",
        "            start_prob = route[i][2]  # Probability at start point\n",
        "            end_prob = route[i + 1][2]  # Probability at end point\n",
        "            avg_prob = (start_prob + end_prob) / 2\n",
        "            # Color gradient: green (low risk) to red (high risk)\n",
        "            if avg_prob < 0.4:\n",
        "                color = \"green\"\n",
        "            elif avg_prob < 0.7:\n",
        "                color = \"yellow\"\n",
        "            else:\n",
        "                color = \"red\"\n",
        "            folium.PolyLine(\n",
        "                locations=[(route[i][0], route[i][1]), (route[i + 1][0], route[i + 1][1])],\n",
        "                color=color,\n",
        "                weight=5,\n",
        "                opacity=0.7,\n",
        "                popup=f\"Route Segment: Probability {avg_prob:.2f}\"\n",
        "            ).add_to(m)\n",
        "\n",
        "    # Add patrol markers for top 5 high-risk areas with enhanced popups\n",
        "    for idx, row in top_5.iterrows():\n",
        "        # Get historical crime data for the area\n",
        "        area_data = df[df['area'] == row['area']]\n",
        "        total_incidents = area_data['incidents'].sum()\n",
        "        common_crime = area_data['crime_type'].mode()[0] if not area_data.empty else \"Unknown\"\n",
        "        popup_html = f\"\"\"\n",
        "        <b>Area:</b> {row['area']}<br>\n",
        "        <b>Predicted Probability:</b> {row['probability']:.2f}<br>\n",
        "        <b>Historical Incidents:</b> {total_incidents}<br>\n",
        "        <b>Most Common Crime:</b> {common_crime}<br>\n",
        "        <b>Recommendation:</b> Patrol every 2 hours\n",
        "        \"\"\"\n",
        "        # Use a car icon to represent patrol (blue if assigned, red if not)\n",
        "        assigned = any(row['area'] == area for area in assignments.values())\n",
        "        icon_color = \"blue\" if assigned else \"red\"\n",
        "        folium.Marker(\n",
        "            location=[row['latitude'], row['longitude']],\n",
        "            popup=folium.Popup(popup_html, max_width=300),\n",
        "            icon=folium.Icon(color=icon_color, icon=\"car\", prefix=\"fa\")\n",
        "        ).add_to(m)\n",
        "\n",
        "    # Render the map in Streamlit\n",
        "    with st.spinner(\"Loading map...\"):\n",
        "        try:\n",
        "            st.components.v1.html(m._repr_html_(), height=600)\n",
        "        except Exception as e:\n",
        "            st.error(f\"Failed to render map in Streamlit: {str(e)}.\")\n",
        "            st.write(\"As a workaround, the map has been saved as 'patrol_map.html'. Please open it in a browser to view the map.\")\n",
        "            try:\n",
        "                m.save(\"patrol_map.html\")\n",
        "            except Exception as save_error:\n",
        "                st.error(f\"Failed to save map as HTML: {str(save_error)}.\")\n",
        "\n",
        "    # Display top 5 high-risk areas\n",
        "    st.subheader(\"Top 5 High-Risk Areas\")\n",
        "    st.dataframe(top_5[['area', 'probability']])\n",
        "    st.write(\"**Recommendation**: Deploy patrols to the above high-risk areas.\")\n",
        "''')\n",
        "\n",
        "# Run Streamlit in the background\n",
        "!streamlit run app.py &>/dev/null &\n",
        "\n",
        "# Create a tunnel with Cloudflared\n",
        "!./cloudflared tunnel --url http://localhost:8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOF8nmfQdZU2CFIK6Bil8CP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}